{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71431aa-848f-430b-b107-af2923d2b370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from baseline_model import load_data_by_year\n",
    "from baseline_model import drop_high_correlation_variables\n",
    "from baseline_model import split_data_by_category\n",
    "from baseline_model import drop_columns_from_data\n",
    "from baseline_model import drop_columns_by_category_and_class\n",
    "from baseline_model import load_aggregated_data\n",
    "from baseline_model import evaluate_model_with_checks\n",
    "from baseline_model import tune_model_with_random_search\n",
    "from baseline_model import evaluate_model_performance_with_cv\n",
    "from baseline_model import tune_logistic_regression\n",
    "from baseline_model import evaluate_model_performance_with_cv_LR\n",
    "from baseline_model import NeuralNet, compute_class_weight, train_model, evaluate_model, tune_neural_network\n",
    "from baseline_model import evaluate_model_with_checks_NN, evaluate_model_performance_with_cv_NN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV, ParameterGrid\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score, precision_score, recall_score,make_scorer, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_classif\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c766bf04-101e-4c65-97b1-fcc992a7a70b",
   "metadata": {},
   "source": [
    "# Step1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275ec48-ee85-4c55-ae48-fba7f06322b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path = \"./\"\n",
    "data_by_year_training, data_by_year_test = load_data_by_year(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee839db8-c2fd-49fa-9fb0-efec0701671e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_by_year_training, data_by_year_test = drop_high_correlation_variables(\n",
    "    \"high_correlation_variables.txt\", data_by_year_training, data_by_year_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292b1502-0e52-4031-86c9-ed827d35668f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = ['CKD', 'CKD_2', 'DIABETES', 'DIABETES_2', 'HYPERTENSION_ESSENTIAL', \n",
    "              'HYPERTENSION_ALL', 'HYPERTENSIVE_DISEASE', 'LIVER_DISEASE', 'CHRONIC_LIVER_DISEASE', \n",
    "              'CIRCULATORY_SYSTEM', 'ISCHEMIC_HEART_DISEASE', 'CONGESTIVE_HEART_FAILURE', 'STROKE', \n",
    "              'CARDIOVASCULAR_DISEASE', 'CANCER', 'COPD', 'PERIPHERAL_VASCULAR', \n",
    "              'NUTRITIONAL_DEFICIENCIES', 'METABOLIC_SYNDROME', 'SUBSTANCE_ABUSE']\n",
    "\n",
    "split_data_by_category(categories, data_by_year_test, data_type=\"test\")\n",
    "split_data_by_category(categories, data_by_year_training, data_type=\"training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa26e77-00db-4d97-a8e0-d91d89bc30e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['CKD', 'CKD_2', 'DIABETES', 'DIABETES_2', 'HYPERTENSION_ESSENTIAL', \n",
    "              'HYPERTENSION_ALL', 'HYPERTENSIVE_DISEASE', 'LIVER_DISEASE', 'CHRONIC_LIVER_DISEASE', \n",
    "              'CIRCULATORY_SYSTEM', 'ISCHEMIC_HEART_DISEASE', 'CONGESTIVE_HEART_FAILURE', 'STROKE', \n",
    "              'CARDIOVASCULAR_DISEASE', 'CANCER', 'COPD', 'PERIPHERAL_VASCULAR', \n",
    "              'NUTRITIONAL_DEFICIENCIES', 'METABOLIC_SYNDROME', 'SUBSTANCE_ABUSE']\n",
    "data_by_year_training = drop_columns_from_data(columns_to_drop, data_by_year_training)\n",
    "data_by_year_test = drop_columns_from_data(columns_to_drop, data_by_year_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bc9f54-cad7-4230-919a-683d3a84b1d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = ['CKD', 'CKD_2', 'DIABETES', 'DIABETES_2', 'HYPERTENSION_ESSENTIAL', \n",
    "              'HYPERTENSION_ALL', 'HYPERTENSIVE_DISEASE', 'LIVER_DISEASE', 'CHRONIC_LIVER_DISEASE', \n",
    "              'CIRCULATORY_SYSTEM', 'ISCHEMIC_HEART_DISEASE', 'CONGESTIVE_HEART_FAILURE', 'STROKE', \n",
    "              'CARDIOVASCULAR_DISEASE', 'CANCER', 'COPD', 'PERIPHERAL_VASCULAR', \n",
    "              'NUTRITIONAL_DEFICIENCIES', 'METABOLIC_SYNDROME', 'SUBSTANCE_ABUSE']\n",
    "\n",
    "columns_to_drop = ['CKD', 'CKD_2', 'DIABETES', 'DIABETES_2', 'HYPERTENSION_ESSENTIAL', \n",
    "              'HYPERTENSION_ALL', 'HYPERTENSIVE_DISEASE', 'LIVER_DISEASE', 'CHRONIC_LIVER_DISEASE', \n",
    "              'CIRCULATORY_SYSTEM', 'ISCHEMIC_HEART_DISEASE', 'CONGESTIVE_HEART_FAILURE', 'STROKE', \n",
    "              'CARDIOVASCULAR_DISEASE', 'CANCER', 'COPD', 'PERIPHERAL_VASCULAR', \n",
    "              'NUTRITIONAL_DEFICIENCIES', 'METABOLIC_SYNDROME', 'SUBSTANCE_ABUSE']\n",
    "\n",
    "drop_columns_by_category_and_class(categories, columns_to_drop, data_type=\"test\")\n",
    "\n",
    "drop_columns_by_category_and_class(categories, columns_to_drop, data_type=\"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5882da05-8afb-43be-bfc0-93cb097fb48f",
   "metadata": {},
   "source": [
    "# Step2 train XG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0cadcb-7a00-40ff-964c-9e907992b643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"/\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 1000],  \n",
    "    'max_depth': [5, 16],  \n",
    "    'learning_rate': [0.01, 0.1],  \n",
    "    'subsample': [0.8,0.9],  \n",
    "    'colsample_bytree': [0.8,0.9]  \n",
    "}\n",
    "\n",
    "param_grid = list(ParameterGrid(param_distributions))\n",
    "comb= len(param_grid)\n",
    "\n",
    "\n",
    "all_hyperparameter_results = []\n",
    "\n",
    "rolling_aggregated_metrics_results = {}\n",
    "source_models_by_year = {}\n",
    "categories = ['CKD', 'CKD_2', 'DIABETES', 'DIABETES_2', 'HYPERTENSION_ESSENTIAL', \n",
    "              'HYPERTENSION_ALL', 'HYPERTENSIVE_DISEASE', 'LIVER_DISEASE', 'CHRONIC_LIVER_DISEASE', \n",
    "              'CIRCULATORY_SYSTEM', 'ISCHEMIC_HEART_DISEASE', 'CONGESTIVE_HEART_FAILURE', 'STROKE', \n",
    "              'CARDIOVASCULAR_DISEASE', 'CANCER', 'COPD', 'PERIPHERAL_VASCULAR', \n",
    "              'NUTRITIONAL_DEFICIENCIES', 'METABOLIC_SYNDROME', 'SUBSTANCE_ABUSE']\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    for class_type in ['1', '0']:  \n",
    "        variable_name = f\"rolling_aggregated_metrics_results_{category}_{class_type}\"\n",
    "        \n",
    "        globals()[variable_name] = {}\n",
    "\n",
    "cutoff_year = 2011\n",
    "data_by_year_totall = pd.concat(\n",
    "    [data_by_year_training[2009], data_by_year_training[2010], data_by_year_training[2011]],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "all_years = sorted(data_by_year_training.keys())\n",
    "update_year=100\n",
    "cutoff_year=2011\n",
    "\n",
    "X_train, y_train = load_aggregated_data(\n",
    "    data_by_year_totall=data_by_year_totall,\n",
    "    data_by_year_training=data_by_year_training,\n",
    "    cutoff_year=cutoff_year,\n",
    "    update_year=update_year\n",
    ")\n",
    "\n",
    "best_model, best_params = tune_model_with_random_search(\n",
    "    param_distributions=param_distributions,\n",
    "    use_scale_pos_weight=True,  \n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    n_iter1=comb\n",
    ")\n",
    "\n",
    "model_path = os.path.join(base_dir, f\"update_{update_year}_best_model_{cutoff_year}.pkl\")\n",
    "joblib.dump(best_model, model_path)\n",
    "source_models_by_year[f\"{cutoff_year}_update_{update_year}\"] = model_path\n",
    "\n",
    "rolling_aggregated_metrics_results[f\"update_{update_year}_{cutoff_year}\"] = {}\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    for class_type in ['1', '0']:\n",
    "        variable_name = f\"rolling_aggregated_metrics_results_{category}_{class_type}\"\n",
    "        results_dict = globals().get(variable_name, {})\n",
    "\n",
    "        if results_dict is None:\n",
    "            print(f\"Variable {variable_name} not initialized.\")\n",
    "            continue\n",
    "\n",
    "        key = f\"update_{update_year}_{cutoff_year}\"\n",
    "        results_dict[key] = {}  \n",
    "\n",
    "        print(f\"  Updated {variable_name} with key={key}\")\n",
    "\n",
    "        globals()[variable_name] = results_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156388e-8c19-492f-b10c-5c213f955c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_storage = {}\n",
    "for test_year in range(2011, 2022):  \n",
    "    if test_year in data_by_year_test:  \n",
    "        print(f\"Testing year: {test_year}\")\n",
    "        \n",
    "        metrics_mean = evaluate_model_performance_with_cv(\n",
    "            data_by_year_test=data_by_year_test,\n",
    "            test_year=test_year,\n",
    "            best_model=best_model,\n",
    "        )\n",
    "        print(f\"Metrics Mean: {metrics_mean}\")\n",
    "        \n",
    "        if metrics_mean:  \n",
    "            rolling_aggregated_metrics_results[f\"update_{update_year}_{cutoff_year}\"][test_year] = {\n",
    "                'AUC': metrics_mean['AUC'],\n",
    "                'PRAUC': metrics_mean['PRAUC'],\n",
    "                'F1-Score': metrics_mean['F1'],\n",
    "                'Precision': metrics_mean['Precision'],\n",
    "                'Recall': metrics_mean['Recall']\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Metrics for year {test_year} are invalid!\")\n",
    "\n",
    "    for category in categories:\n",
    "        for class_type in ['1', '0']:\n",
    "            test_data_variable = f\"data_by_year_test_{category}_{class_type}\"\n",
    "            test_data_dict = globals().get(test_data_variable, {})\n",
    "            \n",
    "            if not test_data_dict or test_year not in test_data_dict:\n",
    "                print(f\"Missing test data for {category}_{class_type} in year {test_year}.\")\n",
    "                continue\n",
    "\n",
    "            metrics_mean = evaluate_model_with_checks(\n",
    "                test_data_dict=test_data_dict,\n",
    "                test_year=test_year,\n",
    "                best_model=best_model,\n",
    "                category=category,\n",
    "                class_type=class_type,\n",
    "            )\n",
    "            #print(f\"Category: {category}, Class: {class_type}, Year: {test_year}, Metrics: {metrics_mean}\")\n",
    "\n",
    "            if category not in results_storage:\n",
    "                results_storage[category] = {}\n",
    "            if class_type not in results_storage[category]:\n",
    "                results_storage[category][class_type] = {}\n",
    "            if test_year not in results_storage[category][class_type]:\n",
    "                results_storage[category][class_type][test_year] = {}\n",
    "\n",
    "            if metrics_mean:  \n",
    "                results_storage[category][class_type][test_year] = {\n",
    "                    'AUC': metrics_mean.get('AUC', None),\n",
    "                    'PRAUC': metrics_mean.get('PRAUC', None),\n",
    "                    'F1-Score': metrics_mean.get('F1', None),\n",
    "                    'Precision': metrics_mean.get('Precision', None),\n",
    "                    'Recall': metrics_mean.get('Recall', None)\n",
    "                }\n",
    "            else:\n",
    "                print(f\"Invalid metrics for {category}_{class_type} in year {test_year}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f6cf4-8d90-4440-a0ad-1de0837ada89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_types = ['1', '0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a976d24-772f-4120-a7f4-b7da5e52ca7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"./\"\n",
    "os.makedirs(base_dir, exist_ok=True) \n",
    "\n",
    "categories_class_types_path = os.path.join(base_dir, 'categories_and_class_types.json')\n",
    "with open(categories_class_types_path, 'w') as f:\n",
    "    json.dump({'categories': categories, 'class_types': class_types}, f)\n",
    "print(f\"Saved categories and class types to {categories_class_types_path}\")\n",
    "\n",
    "results_storage_path = os.path.join(base_dir, 'results_storage.json')\n",
    "with open(results_storage_path, 'w') as f:\n",
    "    json.dump(results_storage, f)\n",
    "print(f\"Saved results_storage to {results_storage_path}\")\n",
    "\n",
    "rolling_results_path = os.path.join(base_dir, 'rolling_aggregated_metrics_results.json')\n",
    "with open(rolling_results_path, 'w') as f:\n",
    "    json.dump(rolling_aggregated_metrics_results, f)\n",
    "print(f\"Saved rolling_aggregated_metrics_results to {rolling_results_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab2c401-a76c-4a08-bb53-4c865914d942",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step3 train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648fa09-d993-4e03-b445-3591492bdf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_LR = \"./\"\n",
    "os.makedirs(base_dir_LR, exist_ok=True)  \n",
    "\n",
    "param_distributions_LR = {\n",
    "    'C': [0.01, 0.1, 1, 10], \n",
    "    'penalty': ['l1'],  \n",
    "    'solver': ['liblinear','saga'],  \n",
    "    'max_iter': [5000],\n",
    "    'tol': [1e-4],\n",
    "}\n",
    "\n",
    "\n",
    "param_grid_LR = list(ParameterGrid(param_distributions_LR))\n",
    "comb_LR = len(param_grid_LR)\n",
    "\n",
    "all_hyperparameter_results_LR = []\n",
    "\n",
    "rolling_aggregated_metrics_results_LR = {}\n",
    "source_models_by_year_LR = {}\n",
    "categories = ['CKD', 'CKD_2', 'DIABETES', 'DIABETES_2', 'HYPERTENSION_ESSENTIAL', \n",
    "              'HYPERTENSION_ALL', 'HYPERTENSIVE_DISEASE', 'LIVER_DISEASE', 'CHRONIC_LIVER_DISEASE', \n",
    "              'CIRCULATORY_SYSTEM', 'ISCHEMIC_HEART_DISEASE', 'CONGESTIVE_HEART_FAILURE', 'STROKE', \n",
    "              'CARDIOVASCULAR_DISEASE', 'CANCER', 'COPD', 'PERIPHERAL_VASCULAR', \n",
    "              'NUTRITIONAL_DEFICIENCIES', 'METABOLIC_SYNDROME', 'SUBSTANCE_ABUSE']\n",
    "\n",
    "for category in categories:\n",
    "    for class_type in ['1', '0']:  \n",
    "        variable_name_LR = f\"rolling_aggregated_metrics_results_{category}_{class_type}_LR\"\n",
    "        \n",
    "        globals()[variable_name_LR] = {}\n",
    "\n",
    "cutoff_year_LR = 2011\n",
    "data_by_year_totall_LR = pd.concat(\n",
    "    [data_by_year_training[2009], data_by_year_training[2010], data_by_year_training[2011]],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "all_years = sorted(data_by_year_training.keys())\n",
    "update_year_LR = 100\n",
    "\n",
    "cutoff_year_LR = 2011\n",
    "\n",
    "X_train_LR, y_train_LR = load_aggregated_data(\n",
    "    data_by_year_totall=data_by_year_totall_LR,\n",
    "    data_by_year_training=data_by_year_training,\n",
    "    cutoff_year=cutoff_year_LR,\n",
    "    update_year=update_year_LR\n",
    ")\n",
    "\n",
    "\n",
    "best_model_LR, best_params_LR = tune_logistic_regression(\n",
    "    param_distributions=param_distributions_LR,\n",
    "    X_train=X_train_LR,\n",
    "    y_train=y_train_LR,\n",
    "    n_iter1=comb_LR\n",
    "    \n",
    ")\n",
    "\n",
    "model_path_LR = os.path.join(base_dir_LR, f\"update_{update_year_LR}_best_model_{cutoff_year_LR}.pkl\")\n",
    "joblib.dump(best_model_LR, model_path_LR)\n",
    "source_models_by_year_LR[f\"{cutoff_year_LR}_update_{update_year_LR}_LR\"] = model_path_LR\n",
    "\n",
    "rolling_aggregated_metrics_results_LR[f\"update_{update_year_LR}_{cutoff_year_LR}\"] = {}\n",
    "\n",
    "for category in categories:\n",
    "    for class_type in ['1', '0']:\n",
    "        variable_name_LR = f\"rolling_aggregated_metrics_results_{category}_{class_type}_LR\"\n",
    "        results_dict_LR = globals().get(variable_name_LR, {})\n",
    "\n",
    "        if results_dict_LR is None:\n",
    "            print(f\"Variable {variable_name_LR} not initialized.\")\n",
    "            continue\n",
    "\n",
    "        key_LR = f\"update_{update_year_LR}_{cutoff_year_LR}\"\n",
    "        results_dict_LR[key_LR] = {}  \n",
    "        print(f\"  Updated {variable_name_LR} with key={key_LR}\")\n",
    "\n",
    "        globals()[variable_name_LR] = results_dict_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d93f0af-81aa-4986-a4b8-8e76907ad134",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_storage_LR = {}\n",
    "\n",
    "for test_year in range(2011, 2022):  \n",
    "    if test_year in data_by_year_test:  \n",
    "        print(f\"Testing year: {test_year} for Logistic Regression\")\n",
    "        \n",
    "        metrics_mean_LR = evaluate_model_performance_with_cv_LR(\n",
    "            data_by_year_test=data_by_year_test,\n",
    "            test_year=test_year,\n",
    "            best_model_LR=best_model_LR,\n",
    "        )\n",
    "        print(f\"Metrics Mean (LR): {metrics_mean_LR}\")\n",
    "        \n",
    "        if metrics_mean_LR: \n",
    "            rolling_aggregated_metrics_results_LR[f\"update_{update_year_LR}_{cutoff_year_LR}\"][test_year] = {\n",
    "                'AUC': metrics_mean_LR['AUC'],\n",
    "                'PRAUC': metrics_mean_LR['PRAUC'],\n",
    "                'F1-Score': metrics_mean_LR['F1'],\n",
    "                'Precision': metrics_mean_LR['Precision'],\n",
    "                'Recall': metrics_mean_LR['Recall']\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Metrics for year {test_year} are invalid for Logistic Regression!\")\n",
    "\n",
    "    for category in categories:\n",
    "        for class_type in ['1', '0']:\n",
    "            test_data_variable_LR = f\"data_by_year_test_{category}_{class_type}\"\n",
    "            test_data_dict_LR = globals().get(test_data_variable_LR, {})\n",
    "            \n",
    "            if not test_data_dict_LR or test_year not in test_data_dict_LR:\n",
    "                print(f\"Missing test data for {category}_{class_type} in year {test_year} (LR).\")\n",
    "                continue\n",
    "\n",
    "            metrics_mean_LR = evaluate_model_with_checks(\n",
    "                test_data_dict=test_data_dict_LR,\n",
    "                test_year=test_year,\n",
    "                best_model=best_model_LR,\n",
    "                category=category,\n",
    "                class_type=class_type,\n",
    "            )\n",
    "\n",
    "            if category not in results_storage_LR:\n",
    "                results_storage_LR[category] = {}\n",
    "            if class_type not in results_storage_LR[category]:\n",
    "                results_storage_LR[category][class_type] = {}\n",
    "            if test_year not in results_storage_LR[category][class_type]:\n",
    "                results_storage_LR[category][class_type][test_year] = {}\n",
    "\n",
    "            if metrics_mean_LR:  \n",
    "                results_storage_LR[category][class_type][test_year] = {\n",
    "                    'AUC': metrics_mean_LR.get('AUC', None),\n",
    "                    'PRAUC': metrics_mean_LR.get('PRAUC', None),\n",
    "                    'F1-Score': metrics_mean_LR.get('F1', None),\n",
    "                    'Precision': metrics_mean_LR.get('Precision', None),\n",
    "                    'Recall': metrics_mean_LR.get('Recall', None)\n",
    "                }\n",
    "            else:\n",
    "                print(f\"Invalid metrics for {category}_{class_type} in year {test_year} (LR)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f02a9-2626-408f-8b9f-b5c67deeb3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_LR = \"./\"\n",
    "os.makedirs(base_dir_LR, exist_ok=True)  \n",
    "\n",
    "categories_class_types_path_LR = os.path.join(base_dir_LR, 'categories_and_class_types_LR.json')\n",
    "with open(categories_class_types_path_LR, 'w') as f:\n",
    "    json.dump({'categories': categories, 'class_types': class_types}, f)\n",
    "print(f\"Saved categories and class types to {categories_class_types_path_LR}\")\n",
    "\n",
    "results_storage_path_LR = os.path.join(base_dir_LR, 'results_storage_LR.json')\n",
    "with open(results_storage_path_LR, 'w') as f:\n",
    "    json.dump(results_storage_LR, f)\n",
    "print(f\"Saved results_storage_LR to {results_storage_path_LR}\")\n",
    "\n",
    "rolling_results_path_LR = os.path.join(base_dir_LR, 'rolling_aggregated_metrics_results_LR.json')\n",
    "with open(rolling_results_path_LR, 'w') as f:\n",
    "    json.dump(rolling_aggregated_metrics_results_LR, f)\n",
    "print(f\"Saved rolling_aggregated_metrics_results_LR to {rolling_results_path_LR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64479274-ba26-4ac6-90e1-24b08612f745",
   "metadata": {},
   "source": [
    "# Step4 train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fab7ee3-15ee-4667-8ff8-45bfe5fca041",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_NN = \"./\"\n",
    "os.makedirs(base_dir_NN, exist_ok=True)  \n",
    "\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [\n",
    "    (512, 256, 128), (256, 128, 64), (128, 64, 32, 16), (512, 128), (256, 64)\n",
    "    ],\n",
    "    'activation': ['relu', 'tanh', 'leaky_relu'],  \n",
    "    'alpha': [0.001, 0.1, 1000],  \n",
    "    'learning_rate': [0.0001,0.001], \n",
    "    'max_iter': [500],  \n",
    "    'batch_size': [64, 128, 256], \n",
    "}\n",
    "\n",
    "\n",
    "cutoff_year_NN = 2011\n",
    "data_by_year_totall_NN = pd.concat(\n",
    "    [data_by_year_training[2009], data_by_year_training[2010], data_by_year_training[2011]],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "all_years = sorted(data_by_year_training.keys())\n",
    "update_year_NN = 100\n",
    "\n",
    "X_train_NN, y_train_NN = load_aggregated_data(\n",
    "    data_by_year_totall=data_by_year_totall_NN,\n",
    "    data_by_year_training=data_by_year_training,\n",
    "    cutoff_year=cutoff_year_NN,\n",
    "    update_year=update_year_NN\n",
    ")\n",
    "\n",
    "X_train_NN = X_train_NN.astype(np.float32)  \n",
    "y_train_NN = y_train_NN.astype(np.float32)\n",
    "\n",
    "X_train_NN = X_train_NN.to_numpy()\n",
    "y_train_NN = y_train_NN.to_numpy()\n",
    "\n",
    "best_model_NN, best_params_NN = tune_neural_network(\n",
    "    X_train=X_train_NN,\n",
    "    y_train=y_train_NN,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=270, \n",
    "    patience=30\n",
    ")\n",
    "\n",
    "model_path_NN = os.path.join(base_dir_NN, \"best_nn_model.pth\")\n",
    "torch.save(best_model_NN.state_dict(), model_path_NN)\n",
    "\n",
    "print(f\"âœ… Best model saved at {model_path_NN}\")\n",
    "print(f\"Best hyperparameters: {best_params_NN}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456a1dc-535a-4c64-ae6b-dccf1029f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_aggregated_metrics_results_NN = {}\n",
    "\n",
    "rolling_aggregated_metrics_results_NN[f\"update_{update_year_NN}_{cutoff_year_NN}\"] = {}\n",
    "\n",
    "for category in categories:\n",
    "    for class_type in ['1', '0']:\n",
    "        variable_name_NN = f\"rolling_aggregated_metrics_results_{category}_{class_type}_NN\"\n",
    "        results_dict_NN = globals().get(variable_name_NN, {})\n",
    "\n",
    "        if results_dict_NN is None:\n",
    "            print(f\"Variable {variable_name_NN} not initialized.\")\n",
    "            continue\n",
    "\n",
    "        key_NN = f\"update_{update_year_NN}_{cutoff_year_NN}\"\n",
    "        results_dict_NN[key_NN] = {}  \n",
    "        print(f\"  Updated {variable_name_NN} with key={key_NN}\")\n",
    "        globals()[variable_name_NN] = results_dict_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228f86e-910d-43fb-95b6-69a98479c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_year in range(2011, 2022):  \n",
    "    if test_year in data_by_year_test: \n",
    "        print(f\"Testing year: {test_year} for Neural Network\")\n",
    "        \n",
    "        metrics_mean_NN = evaluate_model_performance_with_cv_NN(\n",
    "            data_by_year_test=data_by_year_test,\n",
    "            test_year=test_year,\n",
    "            best_model_NN=best_model_NN,\n",
    "        )\n",
    "        print(f\"Metrics Mean (NN): {metrics_mean_NN}\")\n",
    "        \n",
    "        if metrics_mean_NN:  \n",
    "            rolling_aggregated_metrics_results_NN[f\"update_{update_year_NN}_{cutoff_year_NN}\"][test_year] = {\n",
    "                'AUC': metrics_mean_NN['AUC'],\n",
    "                'PRAUC': metrics_mean_NN['PRAUC'],\n",
    "                'F1-Score': metrics_mean_NN['F1'],\n",
    "                'Precision': metrics_mean_NN['Precision'],\n",
    "                'Recall': metrics_mean_NN['Recall']\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Metrics for year {test_year} are invalid for Neural Network!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbea116-072c-4939-bbe1-bf8fb25eee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_storage_NN = {}\n",
    "for test_year in range(2011, 2022):  \n",
    "    if test_year in data_by_year_test: \n",
    "        print(f\"Testing year: {test_year}\")\n",
    "\n",
    "    for category in categories:\n",
    "        for class_type in ['1', '0']:\n",
    "            test_data_variable = f\"data_by_year_test_{category}_{class_type}\"\n",
    "            test_data_dict = globals().get(test_data_variable, {})\n",
    "            \n",
    "            if not test_data_dict or test_year not in test_data_dict:\n",
    "                print(f\"Missing test data for {category}_{class_type} in year {test_year}.\")\n",
    "                continue\n",
    "\n",
    "            metrics_mean = evaluate_model_with_checks_NN(\n",
    "                test_data_dict=test_data_dict,\n",
    "                test_year=test_year,\n",
    "                best_model=best_model_NN,\n",
    "                category=category,\n",
    "                class_type=class_type,\n",
    "            )\n",
    "            #print(f\"Category: {category}, Class: {class_type}, Year: {test_year}, Metrics: {metrics_mean}\")\n",
    "\n",
    "            if category not in results_storage_NN:\n",
    "                results_storage_NN[category] = {}\n",
    "            if class_type not in results_storage_NN[category]:\n",
    "                results_storage_NN[category][class_type] = {}\n",
    "            if test_year not in results_storage_NN[category][class_type]:\n",
    "                results_storage_NN[category][class_type][test_year] = {}\n",
    "\n",
    "            if metrics_mean:  \n",
    "                results_storage_NN[category][class_type][test_year] = {\n",
    "                    'AUC': metrics_mean.get('AUC', None),\n",
    "                    'PRAUC': metrics_mean.get('PRAUC', None),\n",
    "                    'F1-Score': metrics_mean.get('F1', None),\n",
    "                    'Precision': metrics_mean.get('Precision', None),\n",
    "                    'Recall': metrics_mean.get('Recall', None)\n",
    "                }\n",
    "            else:\n",
    "                print(f\"Invalid metrics for {category}_{class_type} in year {test_year}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21529e-01da-420a-8b82-ff956df1fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_NN = \"./\"\n",
    "os.makedirs(base_dir_NN, exist_ok=True)  \n",
    "\n",
    "categories_class_types_path_NN = os.path.join(base_dir_NN, 'categories_and_class_types_NN.json')\n",
    "with open(categories_class_types_path_NN, 'w') as f:\n",
    "    json.dump({'categories': categories, 'class_types': class_types}, f)\n",
    "print(f\"Saved categories and class types to {categories_class_types_path_NN}\")\n",
    "\n",
    "results_storage_path_NN = os.path.join(base_dir_NN, 'results_storage_NN.json')\n",
    "with open(results_storage_path_NN, 'w') as f:\n",
    "    json.dump(results_storage_NN, f)\n",
    "print(f\"Saved results_storage_NN to {results_storage_path_NN}\")\n",
    "\n",
    "rolling_results_path_NN = os.path.join(base_dir_NN, 'rolling_aggregated_metrics_results_NN.json')\n",
    "with open(rolling_results_path_NN, 'w') as f:\n",
    "    json.dump(rolling_aggregated_metrics_results_NN, f)\n",
    "print(f\"Saved rolling_aggregated_metrics_results_NN to {rolling_results_path_NN}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI10",
   "language": "python",
   "name": "aki10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
